<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title><strong>Christine Kwon</strong></title>

    <meta name="author" content="Christine Kwon">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/myimage.JPG"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 0;" alt="profile photo" src="images/myimage.JPG" class="hoverZoomLink"></a>
              </td>
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Christine Kwon
                </p>
                <p>
		Welcome to my personal website! I am a fourth year PhD student in the <a href="https://hcii.cmu.edu/">Human Computer Interaction Institute (HCII) </a> at Carnegie Mellon University advised by <a[...]
				</p>
				<p>
		My research interests center on <span style="color:#0066CC; font-weight:700">educational technologies (EdTech) </span> and <span style="color:#0066CC; font-weight:700">learning sciences </span>.[...]
		My work has primarily focused on how <span style="color:#0066CC; font-weight:700">low-infrastructure and contextually aligned technologies </span> can support out-of-school learning for margnali[...]
		Through my research, I aim to work with educational technologies globally and collaborate with other educators and researchers on providing <span style="color:#0066CC; font-weight:700">meaningfu[...]
                </p>
				<p>
		I am highly interested in research collaborations and connecting with those who share my passion for EdTech research! Please feel free to reach out to discuss potential collaborative opportuniti[...]
				</p>
                <p style="text-align:center">
                  <a href="mailto:ckwon2@andrew.cmu.edu">üìß Email</a> &nbsp;/&nbsp;
                  <a href="data/Christine_Kwon_UPDATED_Jan_2026.pdf">üíº CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=MVPjZeYAAAAJ&hl=en">üéì Scholar</a>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

<tr onmouseout="radmesh_stop()" onmouseover="radmesh_start()">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='radmesh_image'>
        <img src='images/radmesh_after.jpg' width=100%>
      </div>
      <img src='images/radmesh_before.jpg' width=100%>
    </div>
    <script type="text/javascript">
      function radmesh_start() {
        document.getElementById('radmesh_image').style.opacity = "1";
      }

      function radmesh_stop() {
        document.getElementById('radmesh_image').style.opacity = "0";
      }
      radmesh_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://dl.acm.org/doi/abs/10.1145/3698205.3729556">
      <span class="papertitle" style="font-weight:700;font-size:20px;display:block;">Validating a New Approach for Measuring Student Engagement in Remote, Low-Infrastructure Learning Environments</span>
    </a>
    <br>
    Michael W. Asher, <strong> Christine Kwon </strong>, John Stamper, Amy Ogan, Paulo F. Carvalho
    <br>
    <em>Learning@ Scale</em>, 2025
    <br>
    <a href="<a href="https://dl.acm.org/doi/pdf/10.1145/3698205.3729556">" style="display:inline-block;padding:.35rem .6rem;border:2px solid #222;border-radius:6px;font-weight:700;text-decoration:none;color:inherit;">Paper</a>
    <p></p>
    <p>
	In this paper, we introduce a novel solution for studying real-time student engagement with offline learning technology. We present "Prize Codes" as a novel method for measuring student engagement with mobile-learning broadcasts. 
    </p>
  </td>
</tr>

<tr onmouseout="nexf_stop()" onmouseover="nexf_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nexf_image'>
					  <img src='images/nexf_after.jpg' width=100%>
					</div>
          <img src='images/nexf_before.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function nexf_start() {
            document.getElementById('nexf_image').style.opacity = "1";
          }

          function nexf_stop() {
            document.getElementById('nexf_image').style.opacity = "0";
          }
          nexf_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://m-niemeyer.github.io/nexf/">
          <span class="papertitle">NExF: Learning Neural Exposure Fields for View Synthesis</span>
        </a>
        <br>
        Michael Niemeyer,
        Fabian Manhardt,
        Marie-Julie Rakotosaona,
        Michael Oechsle,
        Christina Tsalicoglou,
        Keisuke Tateno,
        <strong>Jonathan T. Barron</strong>,
        Federico Tombari
        <br>
        <em>NeurIPS</em>, 2025
        <br>
        <a href="https://m-niemeyer.github.io/nexf/">project page</a>
        /
        <a href="https://arxiv.org/abs/2510.08279">arXiv</a>
        <p></p>
        <p>
		Learning a neural field that optimizes exposure for each 3D point enables high-quality 3D-consistent view synthesis despite extreme exposure variation during capture.
        </p>
      </td>
    </tr>
	
    <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='bolt3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/bolt3d.mp4" type="video/mp4">
          Your browser does not support the video tag.

          </video></div>
          <img src='images/bolt3d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://szymanowiczs.github.io/bolt3d">
          <span class="papertitle">Bolt3D: Generating 3D Scenes in Seconds</span>
        </a>
        <br>
        Stanislaw Szymanowicz,
        Jason Y. Zhang,
        Pratul Srinivasan,
        Ruiqi Gao,
        Arthur Brussee,
        Aleksander Holynski,
        Ricardo Martin-Brualla,
		<strong>Jonathan T. Barron</strong>,
        Philipp Henzler
        <br>
        <em>ICCV</em>, 2025
        <br>
        <a href="https://szymanowiczs.github.io/bolt3d">project page</a>
        /
        <a href="https://szymanowiczs.github.io/bolt3d">arXiv</a>
        <p></p>
        <p>
		By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds on a single GPU) feed-forward 3D scene generation.
        </p>
      </td>
    </tr>

    <tr onmouseout="ever_stop()" onmouseover="ever_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ever_image'>
					  <img src='images/ever_after.png' width=100%>
					</div>
          <img src='images/ever_before.png' width=100%>
        </div>
        <script type="text/javascript">
          function ever_start() {
            document.getElementById('ever_image').style.opacity = "1";
          }

          function ever_stop() {
            document.getElementById('ever_image').style.opacity = "0";
          }
          ever_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://half-potato.gitlab.io/posts/ever/">
			<span class="papertitle">EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis
</span>
        </a>
        <br>
				Alexander Mai, 
				Peter Hedman,
				George Kopanas,
        Dor Verbin,
        David Futschik,
        Qiangeng Xu,
        Falko Kuester,
				<strong>Jonathan T. Barron</strong>,
        Yinda Zhang
				<br>
        <em>ICCV</em>, 2025 &nbsp <strong>(Oral Presentation)</strong>
        <br>
        <a href="https://half-potato.gitlab.io/posts/ever/">project page</a>
        /
        <a href="https://arxiv.org/abs/2410.01804">arXiv</a>
        <p></p>
        <p>
				Raytracing constant-density ellipsoids yields more accurate and flexible radiance fields than splatting Gaussians, and still runs in real-time.
        </p>
      </td>
    </tr>

    <tr onmouseout="cat4d_stop()" onmouseover="cat4d_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='cat4d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/cat4d.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/cat4d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function cat4d_start() {
            document.getElementById('cat4d_image').style.opacity = "1";
          }

          function cat4d_stop() {
            document.getElementById('cat4d_image').style.opacity = "0";
          }
          cat4d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://cat-4d.github.io/">
			<span class="papertitle">CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models
</span>
        </a>
        <br>
				Rundi Wu,
				Ruiqi Gao,
				Ben Poole,
				Alex Trevithick,
				Changxi Zheng,
				<strong>Jonathan T. Barron</strong>,
				Aleksander Holynski
        <br>
        <em>CVPR</em>, 2025 &nbsp <strong>(Oral Presentation)</strong>
        <br>
        <a href="https://cat-4d.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2411.18613">arXiv</a>
        <p></p>
        <p>
				An approach for turning a video into a 4D radiance field that can be rendered in real-time. When combined with a text-to-video model, this enables text-to-4D.
        </p>
      </td>
    </tr>

    <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='r2r_image'><video  width=100% muted autoplay loop>
          <source src="images/r2r.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/r2r.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function r2r_start() {
            document.getElementById('r2r_image').style.opacity = "1";
          }

          function r2r_stop() {
            document.getElementById('r2r_image').style.opacity = "0";
          }
          r2r_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://relight-to-reconstruct.github.io/">
          <span class="papertitle">Generative Multiview Relighting for
3D Reconstruction under Extreme Illumination Variation</span>
        </a>
        <br>
        Hadi Alzayer,
        Philipp Henzler,
				<strong>Jonathan T. Barron</strong>, 
        Jia-Bin Huang,
        Pratul P. Srinivasan, 
        Dor Verbin
        <br>
        <em>CVPR</em>, 2025 <strong>(Highlight)</strong>
        <br>
        <a href="https://relight-to-reconstruct.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2412.15211">arXiv</a>
        <p></p>
        <p>
				Images taken under extreme illumination variation can be made consistent with diffusion, and this enables high-quality 3D reconstruction.
        </p>
      </td>
    </tr>

    <tr onmouseout="simvs_stop()" onmouseover="simvs_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='simvs_image'><video  width=100% muted autoplay loop>
          <source src="images/simvs.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/simvs.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function simvs_start() {
            document.getElementById('simvs_image').style.opacity = "1";
          }

          function simvs_stop() {
            document.getElementById('simvs_image').style.opacity = "0";
          }
          simvs_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://alextrevithick.github.io/simvs/">
          <span class="papertitle">SimVS: Simulating World Inconsistencies for Robust View Synthesis</span>
        </a>
        <br>
        Alex Trevithick,
        Roni Paiss,
        Philipp Henzler,
        Dor Verbin,
        Rundi Wu,
        Hadi Alzayer,
        Ruiqi Gao,
        Ben Poole,
				<strong>Jonathan T. Barron</strong>, 
        Aleksander Holynski,
        Ravi Ramamoorthi,
        Pratul P. Srinivasan
        <br>
        <em>CVPR</em>, 2025
        <br>
        <a href="https://alextrevithick.github.io/simvs/">project page</a>
        /
        <a href="https://arxiv.org/abs/2412.07696">arXiv</a>
        <p></p>
        <p>
        Simulating the world with video models lets you make inconsistent captures consistent.
        </p>
      </td>
    </tr>

    <tr onmouseout="power_stop()" onmouseover="power_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='power_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/power.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/power.png' width="160">
        </div>
        <script type="text/javascript">
          function power_start() {
            document.getElementById('power_image').style.opacity = "1";
          }

          function power_stop() {
            document.getElementById('power_image').style.opacity = "0";
          }
          power_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://x.com/jon_barron/status/1891918200931061996">
			<span class="papertitle">A Power Transform
</span>
        </a>
        <br>
				<strong>Jonathan T. Barron</strong>
        <br>
        <em>arXiv</em>, 2025
        <br>
        <a href="https://x.com/jon_barron/status/1891918200931061996">tweet</a>
        /
        <a href="https://arxiv.org/abs/2502.10647">arXiv</a>
        <p></p>
        <p>
				A slight tweak to the Box-Cox power transform generalizes a variety of curves, losses, kernel functions, probability distributions, bump functions, and neural network activation functions.
        </p>
      </td>
    </tr>

    <tr onmouseout="cat3d_stop()" onmouseover="cat3d_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='cat3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/cat3d.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/cat3d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function cat3d_start() {
            document.getElementById('cat3d_image').style.opacity = "1";
          }

          function cat3d_stop() {
            document.getElementById('cat3d_image').style.opacity = "0";
          }
          cat3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://cat3d.github.io/">
			<span class="papertitle">CAT3D: Create Anything in 3D with Multi-View Diffusion Models
</span>
        </a>
        <br>
				Ruiqi Gao*,
        Aleksander Holynski*, 
        Philipp Henzler,
        Arthur Brussee, 
				Ricardo Martin Brualla, 
        Pratul P. Srinivasan,
				<strong>Jonathan T. Barron</strong>,
        Ben Poole*
 
        <br>
        <em>NeurIPS</em>, 2024 &nbsp <strong>(Oral Presentation)</strong>
        <br>
        <a href="https://cat3d.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2405.10314">arXiv</a>
        <p></p>
        <p>
				A single model built around diffusion and NeRF that does text-to-3D, image-to-3D, and few-view reconstruction, trains in 1 minute, and renders at 60FPS in a browser.
        </p>
      </td>
    </tr>

    <tr onmouseout="nerfcasting_stop()" onmouseover="nerfcasting_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nerfcasting_image'><video  width=100% muted autoplay loop>
          <source src="images/nerfcasting.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/nerfcasting.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function nerfcasting_start() {
            document.getElementById('nerfcasting_image').style.opacity = "1";
          }

          function nerfcasting_stop() {
            document.getElementById('nerfcasting_image').style.opacity = "0";
          }
          nerfcasting_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://nerf-casting.github.io/">
          <span class="papertitle">NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections</span>
        </a>
        <br>
				
        Dor Verbin,
        Pratul Srinivasan,
				Peter Hedman,
				Benjamin Attal, <br>
				Ben Mildenhall,
				Richard Szeliski,
				<strong>Jonathan T. Barron</strong>
        <br>
        <em>SIGGRAPH Asia</em>, 2024
        <br>
        <a href="https://nerf-casting.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2405.14871">arXiv</a>
        <p></p>
        <p>
        Carefully casting reflection rays lets us synthesize photorealistic specularities in real-world scenes.
        </p>
      </td>
    </tr>

    <tr onmouseout="flash_cache_stop()" onmouseover="flash_cache_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='flash_cache_image'><video  width=100% muted autoplay loop>
          <source src="images/flash_cache_mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/flash_cache.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function flash_cache_start() {
            document.getElementById('flash_cache_image').style.opacity = "1";
          }

          function flash_cache_stop() {
            document.getElementById('flash_cache_image').style.opacity = "0";
          }
          flash_cache_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://benattal.github.io/flash-cache/">
          <span class="papertitle">Flash Cache: Reducing Bias in Radiance Cache Based Inverse Rendering</span>
        </a>
        <br>
				Benjamin Attal,
        Dor Verbin,
        Ben Mildenhall,
        Peter Hedman, <br>
				<strong>Jonathan T. Barron</strong>,
        Matthew O'Toole,
        Pratul P. Srinivasan
        <br>
        <em>ECCV</em>, 2024 &nbsp <strong>(Oral Presentation)</strong>
        <br>
        <a href="https://benattal.github.io/flash-cache/">project page</a>
        /
        <a href="TODO">arXiv</a>
        <p></p>
        <p>
          A more physically-accurate inverse rendering system based on radiance caching for recovering geometry, materials, and lighting from RGB images of an object or scene.
        </p>
      </td>
    </tr>

    <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nuvo_image'><video  width=100% muted autoplay loop>
          <source src="images/nuvo.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/nuvo.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function nuvo_start() {
            document.getElementById('nuvo_image').style.opacity = "1";
          }

          function nuvo_stop() {
            document.getElementById('nuvo_image').style.opacity = "0";
          }
          nuvo_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://pratulsrinivasan.github.io/nuvo/">
          <span class="papertitle">Nuvo: Neural UV Mapping for Unruly 3D Representations</span>
        </a>
        <br>
        Pratul Srinivasan,
        Stephan J. Garbin,
        Dor Verbin,
		<strong>Jonathan T. Barron</strong>,
        Ben Mildenhall
        <br>
        <em>ECCV</em>, 2024
        <br>
        <a href="https://pratulsrinivasan.github.io/nuvo/">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=hmJiOSTDQZI">video</a>
        /
        <a href="http://arxiv.org/abs/2312.05283">arXiv</a>
        <p></p>
        <p>
        Neural fields let you recover editable UV mappings for the challenging geometries produced by NeRF-like models.
        </p>
      </td>
    </tr>

    <tr onmouseout="bog_stop()" onmouseover="bog_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='bog_image'><video  width=100% muted autoplay loop>
          <source src="images/bog.jpg" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/bog.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function bog_start() {
            document.getElementById('bog_image').style.opacity = "1";
          }

          function bog_stop() {
            document.getElementById('bog_image').style.opacity = "0";
          }
          bog_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://creiser.github.io/binary_opacity_grid/">
          <span class="papertitle">Binary Opacity Grids: Capturing Fine Geometric Detail for Mesh-Based View Synthesis
</span>
        </a>
        <br>
				Christian Reiser,
				Stephan J. Garbin,
				Pratul Srinivasan,
				Dor Verbin,
				Richard Szeliski,
				Ben Mildenhall,
				<strong>Jonathan T. Barron</strong>,
				Peter Hedman*,
				Andreas Geiger*		
        <br>
        <em>SIGGRAPH</em>, 2024
        <br>
        <a href="https://creiser.github.io/binary_opacity_grid/">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=2TPUmGRg8bM">video</a>
        /
        <a href="https://arxiv.org/abs/2402.12377">arXiv</a>
        <p></p>
        <p>
        Applying anti-aliasing to a discrete opacity grid lets you render a hard representation into a soft image, and this enables highly-detailed mesh recovery.
        </p>
      </td>
    </tr>

    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='smerf_image'><video  width=100% muted autoplay loop>
          <source src="images/smerf.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/smerf.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function smerf_start() {
            document.getElementById('smerf_image').style.opacity = "1";
          }

          function smerf_stop() {
            document.getElementById('smerf_image').style.opacity = "0";
          }
          smerf_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://smerf-3d.github.io/">
          <span class="papertitle">SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration</span>
        </a>
        <br>
		Daniel Duckworth*,
		Peter Hedman*,
		Christian Reiser,
		Peter Zhizhin,
		Jean-Fran√ßois Thibert,
        Mario Luƒçiƒá,
        Richard Szeliski,
		<strong>Jonathan T. Barron</strong>
        <br>
        <em>SIGGRAPH</em>, 2024 &nbsp <strong>(Honorable Mention)</strong>
        <br>
        <a href="https://smerf-3d.github.io/">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a>
        /
        <a href="https://arxiv.org/abs/2312.07541">arXiv</a>
        <p></p>
        <p>
        Distilling a Zip-NeRF into a tiled set of MERFs lets you fly through radiance fields on laptops and smartphones at 60 FPS.
        </p>
      </td>
    </tr>
	

  <tr onmouseout="eclipse_stop()" onmouseover="eclipse_start()">
    <td style="padding:16px;width:20%;vertical-align:middle">
      <div class="one">
        <div class="two" id='eclipse_image'><video  width=100% height=100% muted autoplay loop>
        <source src="images/eclipse_after.mp4" type="video/mp4">
        Your browser does not support the video tag.
        </video></div>
        <img src='images/eclipse_before.jpg' width="160">
      </div>
      <script type="text/javascript">
        function eclipse_start() {
          document.getElementById('eclipse_image').style.opacity = "1";
        }

        function eclipse_stop() {
          document.getElementById('eclipse_image').style.opacity = "0";
        }
        eclipse_stop()
      </script>
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
      <a href="https://dorverbin.github.io/eclipse">
        <span class="papertitle">Eclipse: Disambiguating Illumination and Materials using Unintended Shadows</span>
      </a>
      <br>
      Dor Verbin,
      Ben Mildenhall,
      Peter Hedman, <br>
      <strong>Jonathan T. Barron</strong>,
      Todd Zickler,
      Pratul Srinivasan
      <br>
      <em>CVPR</em>, 2024 &nbsp <strong>(Oral Presentation)</strong>
      <br>
      <a href="https://dorverbin.github.io/eclipse">project page</a>
      /
      <a href="https://www.youtube.com/watch?v=amQLGyza3EU">video</a>
      /
      <a href="https://arxiv.org/abs/2305.16321">arXiv</a>
      <p></p>
      <p>
      Shadows cast by unobserved occluders provide a high-frequency cue for recovering illumination and materials.
      </p>
    </td>
  </tr>

  <tr onmouseout="recon_stop()" onmouseover="recon_start()">
    <td style="padding:16px;width:20%;vertical-align:middle">
      <div class="one">
        <div class="two" id='recon_image'><video  width=100% height=100% muted autoplay loop>
        <source src="images/recon.mp4" type="video/mp4">
        Your browser does not support the video tag.
        </video></div>
        <img src='images/recon.jpg' width="160">
      </div>
      <script type="text/javascript">
        function recon_start() {
          document.getElementById('recon_image').style.opacity = "1";
        }

        function recon_stop() {
          document.getElementById('recon_image').style.opacity = "0";
        }
        recon_stop()
      </script>
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
      <a href="https://reconfusion.github.io/">
		<span class="papertitle">ReconFusion: 3D Reconstruction with Diffusion Priors</span>
      </a>
      <br>
      Rundi Wu*,
	Ben Mildenhall*,
      Philipp Henzler,
      Keunhong Park,
      Ruiqi Gao,
      Daniel Watson,
      Pratul P. Srinivasan,
      Dor Verbin,
	<strong>Jonathan T. Barron</strong>,
      Ben Poole,
      Aleksander Holynski*
      <br>
      <em>CVPR</em>, 2024
      <br>
      <a href="https://reconfusion.github.io/">project page</a>
      /
      <a href="https://arxiv.org/abs/2312.02981">arXiv</a>
      <p></p>
      <p>
      Using a multi-image diffusion model as a regularizer lets you recover high-quality radiance fields from just a handful of images.
      </p>
    </td>
  </tr>

  <tr onmouseout="shinobi_stop()" onmouseover="shinobi_start()">
    <td style="padding:16px;width:20%;vertical-align:middle">
      <div class="one">
        <div class="two" id='shinobi_image'><video  width=100% muted autoplay loop>
        <source src="images/shinobi.mp4" type="video/mp4">
        Your browser does not support the video tag.
        </video></div>
        <img src='images/shinobi.jpg' width=100%>
      </div>
      <script type="text/javascript">
        function shinobi_start() {
          document.getElementById('shinobi_image').style.opacity = "1";
        }

        function shinobi_stop() {
          document.getElementById('shinobi_image').style.opacity = "0";
        }
        shinobi_stop()
      </script>
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
      <a href="https://shinobi.aengelhardt.com/">
        <span class="papertitle">SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-Wild</span>
      </a>
      <br>
			
			Andrea[...]
			Amit Raj, 
			Mark Boss, 
			Yunzhi Zhang, 
			Abhishek Kar, 
			Yuanzhen Li, 
			Deqing Sun, 
			Ricardo Martin Brualla, 
      <strong>Jonathan T. Barron</strong>,
			[...]
			Varun Jampani
      <br>
      <em>CVPR</em>, 2024
      <br>
      <a href="https://shinobi.aengelhardt.com/">project page</a>
      /
      <a href="https://www.youtube.com/watch?v=m_5kvtlDnl4">video</a>
      /
      <a href="https://arxiv.org/abs/2401.10171">arXiv</a>
      <p></p>
      <p>
      A class-agnostic inverse rendering solution for turning in-the-wild images of an object into a relightable 3D asset.
      </p>
    </td>
  </tr>
	
    <tr onmouseout="internerf_stop()" onmouseover="internerf_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
 					  <img src='images/internerf_after.jpg' width=100%>
 					</div>
          <img src='images/internerf_before.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function internerf_start() {
            document.getElementById('internerf_image').style.opacity = "1";
          }

          function internerf_stop() {
            document.getElementById('internerf_image').style.opacity = "0";
          }
          internerf_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2406.11737">
          <span class="papertitle">InterNeRF: Scaling Radiance Fields via Parameter Interpolation</span>
        </a>
        <br>
		Clinton Wang,
		Peter Hedman,
		Polina Golland,
		<strong>Jonathan T. Barron</strong>,
		Daniel Duckworth
        <br>
        <em>CVPR Neural Rendering Intelligence</em>, 2024
        <br>
        <a href="https://arxiv.org/abs/2406.11737">arXiv</a>
        <p></p>
        <p>
        Parameter interpolation enables high-quality large-scale scene reconstruction and out-of-core training and rendering.
        </p>
      </td>
    </tr>

<tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
    <div class="two" id='difsurvey_image'><video  width=100% height=100% muted autoplay loop>
    <source src="images/difsurvey_video.mp4" type="video/mp4">
    Your browser does not support the video tag.
    </video></div>
      <img src='images/difsurvey_image.jpg' width="160">
    </div>
    <script type="text/javascript">
      function difsurvey_start() {
        document.getElementById('difsurvey_image').style.opacity = "1";
      }

      function difsurvey_stop() {
        document.getElementById('difsurvey_image').style.opacity = "0";
      }
      difsurvey_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://arxiv.org/abs/2310.07204">
      <span class="papertitle">State of the Art on Diffusion Models for Visual Computing
</span>
    </a>
    <br>
		Ryan Po,
		Wang Yifan,
		Vladislav Golyanik,
		Kfir Aberman,
		<strong>Jonathan T. Barron</strong>,
		Amit H. Bermano,
		Eric Ryan Chan,
		Tali Dekel,
		Aleksander Holynski,
		Angjoo Kanazawa,
		C. Karen Liu,
		Lingjie Liu,
		Ben Mildenhall,
        Matthias Nie√üner,
		Bj√∂rn Ommer,
		Christian Theobalt,
		Peter Wonka,
        Gordon Wetzstein
    <br>
	<em>Eurographics State-of-the-Art Report<em>, 2024
    <br>
    <p></p>
    <p>
    A survey of recent progress in diffusion models for images, videos, and 3D.
    </p>
  </td>
</tr>          

    <tr onmouseout="camp_stop()" onmouseover="camp_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='camp_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/camp.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/camp.png' width="160">
        </div>
        <script type="text/javascript">
          function camp_start() {
            document.getElementById('camp_image').style.opacity = "1";
          }

          function camp_stop() {
            document.getElementById('camp_image').style.opacity = "0";
          }
          camp_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://camp-nerf.github.io/">
          <span class="papertitle">CamP: Camera Preconditioning for Neural Radiance Fields</span>
        </a>
        <br>
        Keunhong Park,
        Philipp Henzler,
        Ben Mildenhall,
        <strong>Jonathan T. Barron</strong>,
        Ricardo Martin-Brualla
        <br>
        <em>SIGGRAPH Asia</em>, 2023
        <br>
        <a href="https://camp-nerf.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2308.10902">arXiv</a>
        <p></p>
        <p>
        Preconditioning based on camera parameterization helps NeRF and camera extrinsics/intrinsics optimize better together.
        </p>
      </td>
    </tr>
<!-- remainder of index content unchanged -->
...
</tbody></table>
</td></tr></tbody></table>
  </body>
</html>
